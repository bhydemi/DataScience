{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Label Classification on Reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /Users/bhydemi/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk_packages = [\n",
    "    (\"reuters\", \"corpora/reuters.zip\"),\n",
    "    (\"punkt\", \"tokenizers/punkt\")\n",
    "]\n",
    "\n",
    "for pid, fid in nltk_packages:\n",
    "    try:\n",
    "        nltk.data.find(fid)\n",
    "    except LookupError:\n",
    "        nltk.download(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the dataset from nltk.corpus\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data imported from nltk is being splitted into train and test, so also their corresponding documents and categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents, train_categories = zip(*[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('training/')])\n",
    "test_documents, test_categories = zip(*[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('test/')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import neccessary libraries \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "#filter warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#Assign stopwords to stopwords variables\n",
    "stopwords = stopwords.words(\"english\")\n",
    "#Initialize Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING, EXTRACTION AND TEXT PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words was used for feature extraction.The total words in the whole document was extracted and frequency of each word was taken note of. From observation, words with minimum number of occurence of 137 resulted in a total feature of approximately 1000, which was used in modelling. This way, weights are being assigned to each words based on frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(documents):\n",
    "    large_collection = []\n",
    "    for document in documents:\n",
    "        for text in document:\n",
    "            #tokenize each article in a document\n",
    "            word_tok = word_tokenize(text)\n",
    "            #removal of stopwords \n",
    "            word_tok = [word for word in word_tok if word not in stopwords]\n",
    "            #Lemmatizing of words\n",
    "            word_stemed = [lemmatizer.lemmatize(word.lower()) for word in word_tok]\n",
    "            #regex to remove numbers etc\n",
    "            regex = re.compile('[a-zA-Z]+')\n",
    "            all_words = list(filter(lambda token:regex.match(token),word_stemed))\n",
    "            large_collection += all_words\n",
    "    #Count the frequency of occurence of each word\n",
    "    word_freq = Counter(large_collection)\n",
    "    features = []\n",
    "    for w in word_freq:\n",
    "        if word_freq[w] >=137: \n",
    "            features.append(w)\n",
    "    #generate a top 1000 features in terms of frequency\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_set(document, features):\n",
    "    #The frequnency of each word in the  whole corpus derived\n",
    "    featureset=[]\n",
    "    for text in document:\n",
    "        current_text = word_tokenize(text.lower())\n",
    "        text_stemmed = [lemmatizer.lemmatize(word) for word in current_text]\n",
    "        regex = re.compile('[a-zA-Z]+')\n",
    "        all_words = list(filter(lambda token:regex.match(token),text_stemmed))\n",
    "        #get an array of zeros from the features\n",
    "        feat = np.zeros(len(features))\n",
    "        for word in all_words:\n",
    "            #check for each word in the article in the top 1000 features generated.\n",
    "            #if exist therefore its frequency is counted\n",
    "            if word.lower() in features:\n",
    "                index_val = features.index(word.lower())\n",
    "                feat[index_val] += 1\n",
    "        feat = list(feat)\n",
    "        featureset.append(feat)\n",
    "    # A matrix of frequency of top 1000 features' presence in each article per test and train\n",
    "    return featureset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_test_data(test_documents, train_documents, test_categories,train_categories):\n",
    "    # The MultiLabelBinarizer will convert the categories from each article\n",
    "    # into a vector with 0 or 1 depending if the article is from the category or not.\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit(train_categories + test_categories)\n",
    "    y_train = mlb.transform(train_categories)\n",
    "    y_test = mlb.transform(test_categories)\n",
    "    #Top 100 features of the corpus will be generated\n",
    "    features = processing([test_documents, train_documents])\n",
    "    #The train and test features will be generated\n",
    "    X_train = get_features_set(train_documents, features)\n",
    "    X_test = get_features_set(test_documents, features)\n",
    "    \n",
    "    return X_train, X_test, y_test, y_train, mlb, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_test, y_train, mlb, features = gen_train_test_data(test_documents, train_documents, \n",
    "                                                                      test_categories, train_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converted the data into a numpy array\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELLING USING KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple neural network was used to create the classifier. With an output activation Sigmoid due to the nature of Multilabel classification i.e binary classification. Due to simplicity Keras was chosen in implementing the Neural networks and it's simplicity in the learning algorithm.\n",
    "Neural network with inpute node of 1002 and output node of 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1116be518>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_dim=X_train.shape[1]))\n",
    "#Dropout to prevent overfitting\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "#Dropout to prevent overfitting#Dropout to prevent overfitting\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=2, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=2, save_best_only=True) # save best model\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),verbose=0,epochs=400, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTERPRETATION OF RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy, recall, precision and f1-score metrics are being used to determine the performance of the model.\n",
    "The macro-average is being used because we want to determine how the model performs overall across the whole corpus.\n",
    "\n",
    "Accuracy of 78% doesn't provide us with enough detail in terms of model performance.It is simply a ratio of correctly predicted observation to the total observations.\n",
    "\n",
    "A precision of 51.69% meaning, 51.69% of all predicted categories actually belong to the category. This relates inversely to false positive rate.\n",
    "\n",
    "A recall of 31.78 %, meaning of all actual categories only 31.78% was predicted right. This relates to false negative.\n",
    "\n",
    "F1-score is the weighted average of both precision and recall. Therefore, this score takes both false positives and false negatives into account.\n",
    "\n",
    "It's difficult to acheive high precision and recall due to trade-offs between the two metrics. For example in our results a well above averge was gotten for precision while below average recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.7797283868830739\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "preds = model.predict(X_test)\n",
    "preds[preds>=0.5] = 1\n",
    "preds[preds<0.5] = 0\n",
    "score = metrics.accuracy_score(preds, y_test)\n",
    "print(\"Final accuracy: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7797\n",
      "Precision: 0.5221\n",
      "Recall   : 0.3321\n",
      "F1-Score : 0.3885\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : {:.4f}\".format(metrics.accuracy_score(y_test, preds)))\n",
    "print(\"Precision: {:.4f}\".format(metrics.precision_score(y_test, preds, average='macro')))\n",
    "print(\"Recall   : {:.4f}\".format(metrics.recall_score(y_test, preds, average='macro')))\n",
    "print(\"F1-Score : {:.4f}\".format(metrics.f1_score(y_test, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "            acq       0.96      0.93      0.95       719\n",
      "           alum       0.83      0.22      0.34        23\n",
      "         barley       0.86      0.43      0.57        14\n",
      "            bop       0.75      0.60      0.67        30\n",
      "        carcass       0.40      0.22      0.29        18\n",
      "     castor-oil       0.00      0.00      0.00         1\n",
      "          cocoa       0.94      0.89      0.91        18\n",
      "        coconut       0.00      0.00      0.00         2\n",
      "    coconut-oil       0.00      0.00      0.00         3\n",
      "         coffee       0.93      0.96      0.95        28\n",
      "         copper       1.00      0.72      0.84        18\n",
      "     copra-cake       0.00      0.00      0.00         1\n",
      "           corn       0.84      0.77      0.80        56\n",
      "         cotton       0.92      0.60      0.73        20\n",
      "     cotton-oil       0.00      0.00      0.00         2\n",
      "            cpi       0.67      0.36      0.47        28\n",
      "            cpu       0.00      0.00      0.00         1\n",
      "          crude       0.89      0.86      0.87       189\n",
      "            dfl       0.00      0.00      0.00         1\n",
      "            dlr       0.81      0.68      0.74        44\n",
      "            dmk       0.00      0.00      0.00         4\n",
      "           earn       0.97      0.99      0.98      1087\n",
      "           fuel       0.50      0.10      0.17        10\n",
      "            gas       1.00      0.59      0.74        17\n",
      "            gnp       0.90      0.77      0.83        35\n",
      "           gold       0.95      0.60      0.73        30\n",
      "          grain       0.92      0.87      0.89       149\n",
      "      groundnut       0.00      0.00      0.00         4\n",
      "  groundnut-oil       0.00      0.00      0.00         1\n",
      "           heat       1.00      0.60      0.75         5\n",
      "            hog       1.00      0.33      0.50         6\n",
      "        housing       1.00      0.50      0.67         4\n",
      "         income       1.00      0.43      0.60         7\n",
      "    instal-debt       0.00      0.00      0.00         1\n",
      "       interest       0.78      0.62      0.69       131\n",
      "            ipi       0.82      0.75      0.78        12\n",
      "     iron-steel       0.45      0.36      0.40        14\n",
      "            jet       0.00      0.00      0.00         1\n",
      "           jobs       0.85      0.52      0.65        21\n",
      "       l-cattle       0.00      0.00      0.00         2\n",
      "           lead       1.00      0.07      0.13        14\n",
      "            lei       1.00      1.00      1.00         3\n",
      "        lin-oil       0.00      0.00      0.00         1\n",
      "      livestock       0.65      0.46      0.54        24\n",
      "         lumber       0.00      0.00      0.00         6\n",
      "      meal-feed       0.38      0.16      0.22        19\n",
      "       money-fx       0.82      0.72      0.77       179\n",
      "   money-supply       0.74      0.74      0.74        34\n",
      "        naphtha       0.00      0.00      0.00         4\n",
      "        nat-gas       0.87      0.43      0.58        30\n",
      "         nickel       0.00      0.00      0.00         1\n",
      "            nkr       0.00      0.00      0.00         2\n",
      "          nzdlr       0.00      0.00      0.00         2\n",
      "            oat       0.50      0.17      0.25         6\n",
      "        oilseed       0.61      0.53      0.57        47\n",
      "         orange       0.67      0.18      0.29        11\n",
      "      palladium       0.00      0.00      0.00         1\n",
      "       palm-oil       0.83      0.50      0.62        10\n",
      "     palmkernel       0.00      0.00      0.00         1\n",
      "       pet-chem       1.00      0.17      0.29        12\n",
      "       platinum       0.00      0.00      0.00         7\n",
      "         potato       0.00      0.00      0.00         3\n",
      "        propane       0.00      0.00      0.00         3\n",
      "           rand       0.00      0.00      0.00         1\n",
      "       rape-oil       0.50      0.33      0.40         3\n",
      "       rapeseed       1.00      0.44      0.62         9\n",
      "       reserves       0.85      0.61      0.71        18\n",
      "         retail       1.00      0.50      0.67         2\n",
      "           rice       1.00      0.33      0.50        24\n",
      "         rubber       1.00      0.67      0.80        12\n",
      "            rye       0.00      0.00      0.00         1\n",
      "           ship       0.87      0.66      0.75        89\n",
      "         silver       0.00      0.00      0.00         8\n",
      "        sorghum       0.67      0.20      0.31        10\n",
      "       soy-meal       0.50      0.08      0.13        13\n",
      "        soy-oil       0.50      0.18      0.27        11\n",
      "        soybean       0.69      0.61      0.65        33\n",
      "strategic-metal       0.00      0.00      0.00        11\n",
      "          sugar       0.96      0.61      0.75        36\n",
      "       sun-meal       0.00      0.00      0.00         1\n",
      "        sun-oil       0.00      0.00      0.00         2\n",
      "        sunseed       1.00      0.20      0.33         5\n",
      "            tea       0.00      0.00      0.00         4\n",
      "            tin       1.00      0.67      0.80        12\n",
      "          trade       0.84      0.68      0.75       117\n",
      "        veg-oil       0.81      0.46      0.59        37\n",
      "          wheat       0.82      0.76      0.79        71\n",
      "            wpi       1.00      0.50      0.67        10\n",
      "            yen       0.00      0.00      0.00        14\n",
      "           zinc       0.00      0.00      0.00        13\n",
      "\n",
      "    avg / total       0.87      0.78      0.81      3744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true=y_test, y_pred=preds, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(text):\n",
    "    # Extract features\n",
    "    current_text = word_tokenize(text.lower())\n",
    "    text_stemmed = [lemmatizer.lemmatize(word) for word in current_text]\n",
    "    regex = re.compile('[a-zA-Z]+')\n",
    "    all_words = list(filter(lambda token:regex.match(token),text_stemmed))\n",
    "    feat = np.zeros(len(features))\n",
    "    for word in all_words:\n",
    "        if word.lower() in features:\n",
    "            index_val = features.index(word.lower())\n",
    "            feat[index_val] += 1\n",
    "    feat = np.asarray([feat])\n",
    "    \n",
    "    # # Do prediction\n",
    "    pred = model.predict(feat)\n",
    "    pred[pred>=0.5] = 1\n",
    "    pred[pred<0.5] = 0\n",
    "\n",
    "    # Convert predictions back to labels\n",
    "    labels = mlb.inverse_transform(pred)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('money-supply',)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(train_documents[111])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction and engineering was done using bag of words by getting the top 1000 words based on frequency. The lables were converted by using the MultiLabelBinarizer from sklearn to a vector with 0 or 1 depending if the article is from the category or not. The features alongside the lable were passed into a 3 layer Neural network. The model derived was then evaluated based on precision, accuracy, recall and f1-score. The resulting accuracy gotten was 78.11%, precision 51.7%, Recall of 31.87%, and F1-score of 37.3%. \n",
    "\n",
    "\n",
    " Large amount of data would improve on this approach because neural networks perform well with large dataset.Futher works can be done in area of tuning the number of nodes and layers in the Neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
